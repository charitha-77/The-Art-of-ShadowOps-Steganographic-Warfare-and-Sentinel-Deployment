{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "y = np.eye(3)[y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = 10 \n",
    "output_size = y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    global z1, a1, z2, a2\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, y, output):\n",
    "    global W1, b1, W2, b2\n",
    "    error = output - y\n",
    "    dW2 = np.dot(a1.T, error)\n",
    "    db2 = np.sum(error, axis=0, keepdims=True)\n",
    "    dW1 = np.dot(X.T, np.dot(error, W2.T) * sigmoid_derivative(a1))\n",
    "    db1 = np.sum(np.dot(error, W2.T) * sigmoid_derivative(a1), axis=0)\n",
    "    \n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.5726181870291935\n",
      "Epoch 50, Loss: 0.5061102801789394\n",
      "Epoch 100, Loss: 0.4720298850878603\n",
      "Epoch 150, Loss: 0.31971184262047697\n",
      "Epoch 200, Loss: 0.43608732684920365\n",
      "Epoch 250, Loss: 0.26783820479918974\n",
      "Epoch 300, Loss: 0.47715729713757987\n",
      "Epoch 350, Loss: 0.23870507639858782\n",
      "Epoch 400, Loss: 0.3872259339528161\n",
      "Epoch 450, Loss: 0.15177051060916666\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    output = forward(X_train)\n",
    "    backward(X_train, y_train, output)\n",
    "    if epoch % 50 == 0:\n",
    "        loss = -np.mean(np.log(output[np.arange(len(y_train)), np.argmax(y_train, axis=1)]))\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    output = forward(X)\n",
    "    return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = predict(X_train)\n",
    "train_accuracy = np.mean(train_predictions == np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = predict(X_test)\n",
    "test_accuracy = np.mean(test_predictions == np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 67.50%\n",
      "Testing accuracy: 63.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Training accuracy: {train_accuracy * 100:.2f}%')\n",
    "print(f'Testing accuracy: {test_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
